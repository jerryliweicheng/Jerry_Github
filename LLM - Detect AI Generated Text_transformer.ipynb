{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":4620664,"sourceType":"datasetVersion","datasetId":2663421}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-24T15:16:39.984041Z","iopub.execute_input":"2023-11-24T15:16:39.984643Z","iopub.status.idle":"2023-11-24T15:16:40.536844Z","shell.execute_reply.started":"2023-11-24T15:16:39.984609Z","shell.execute_reply":"2023-11-24T15:16:40.535567Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/spm.model\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/config.json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/README (1).md\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/README.md\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/tokenizer_config (1).json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/trainer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/run_test.sh\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/run_train.sh\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/trainer_state.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/eval_results.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/training_args.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/all_results.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/test_results.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/spm.model\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/config.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/trainer_state.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/training_args.bin\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/scaler.pt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/scheduler.pt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/optimizer.pt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/rng_state.pth\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/rust_model.ot\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/pytorch_model.generator.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/generator_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/spm.model\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/config.json\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/README.md\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/gitattributes.txt\n/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv\n/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\n/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\n/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\n/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\nimport datasets\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:40.539629Z","iopub.execute_input":"2023-11-24T15:16:40.540225Z","iopub.status.idle":"2023-11-24T15:16:47.095338Z","shell.execute_reply.started":"2023-11-24T15:16:40.540178Z","shell.execute_reply":"2023-11-24T15:16:47.094352Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall\"","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:47.096698Z","iopub.execute_input":"2023-11-24T15:16:47.097344Z","iopub.status.idle":"2023-11-24T15:16:47.103797Z","shell.execute_reply.started":"2023-11-24T15:16:47.097302Z","shell.execute_reply":"2023-11-24T15:16:47.102447Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:47.106402Z","iopub.execute_input":"2023-11-24T15:16:47.106855Z","iopub.status.idle":"2023-11-24T15:16:47.114385Z","shell.execute_reply.started":"2023-11-24T15:16:47.106825Z","shell.execute_reply":"2023-11-24T15:16:47.113536Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:47.116069Z","iopub.execute_input":"2023-11-24T15:16:47.116771Z","iopub.status.idle":"2023-11-24T15:16:49.618253Z","shell.execute_reply.started":"2023-11-24T15:16:47.116729Z","shell.execute_reply":"2023-11-24T15:16:49.616994Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train = df[df.prompt_name != 'Car-free cities'].reset_index(drop=True)\nvalid = df[df.prompt_name == 'Car-free cities'].reset_index(drop=True)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:49.620314Z","iopub.execute_input":"2023-11-24T15:16:49.620731Z","iopub.status.idle":"2023-11-24T15:16:49.678716Z","shell.execute_reply.started":"2023-11-24T15:16:49.620696Z","shell.execute_reply":"2023-11-24T15:16:49.677540Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                text  label  \\\n0  Phones\\n\\nModern humans today are always on th...      0   \n1  This essay will explain if drivers should or s...      0   \n2  Driving while the use of cellular devices\\n\\nT...      0   \n3  Phones & Driving\\n\\nDrivers should not be able...      0   \n4  Cell Phone Operation While Driving\\n\\nThe abil...      0   \n\n          prompt_name           source  RDizzl3_seven  \n0  Phones and driving  persuade_corpus          False  \n1  Phones and driving  persuade_corpus          False  \n2  Phones and driving  persuade_corpus          False  \n3  Phones and driving  persuade_corpus          False  \n4  Phones and driving  persuade_corpus          False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>prompt_name</th>\n      <th>source</th>\n      <th>RDizzl3_seven</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones\\n\\nModern humans today are always on th...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices\\n\\nT...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"not_persuade_df = train[train['source'] != 'persuade_corpus']\npersuade_df = train[train['source'] == 'persuade_corpus']\nsampled_persuade_df = persuade_df.sample(n=6000, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:49.680048Z","iopub.execute_input":"2023-11-24T15:16:49.680908Z","iopub.status.idle":"2023-11-24T15:16:49.711456Z","shell.execute_reply.started":"2023-11-24T15:16:49.680875Z","shell.execute_reply":"2023-11-24T15:16:49.710575Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"all_human = set(list(''.join(sampled_persuade_df.text.to_list())))\nother = set(list(''.join(not_persuade_df.text.to_list())))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:49.715965Z","iopub.execute_input":"2023-11-24T15:16:49.716762Z","iopub.status.idle":"2023-11-24T15:16:51.450549Z","shell.execute_reply.started":"2023-11-24T15:16:49.716712Z","shell.execute_reply":"2023-11-24T15:16:51.447758Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"chars_to_remove = ''.join([x for x in other if x not in all_human])\nprint(chars_to_remove)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:51.452268Z","iopub.execute_input":"2023-11-24T15:16:51.453157Z","iopub.status.idle":"2023-11-24T15:16:51.459208Z","shell.execute_reply.started":"2023-11-24T15:16:51.453118Z","shell.execute_reply":"2023-11-24T15:16:51.457959Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"ğŸ§ğŸ“°ğŸ™…ğŸ›‹ğŸš”Â­ğŸ™Œå¿…ğŸ˜®ğŸ¢ğŸ˜ˆğŸ“·ğŸ’­ğŸğŸŒŸğŸ‘ŒğŸ¥˜è·¯ğŸŒ²è¯¥ğŸ…ğŸ•ğŸ“–ğŸ˜ŒğŸ§½ğŸš—ğŸ› ÄğŸ‘ğŸŒğŸ¥ä½¿ğŸğŸ¥ªä¸Šã¡åº”ğŸ§¹ğŸ³ğŸ¦â™‚ğŸŸğŸ˜²ğŸ”­ğŸ¥¶ğŸ¤ªğŸğŸ¶â˜¹ğŸ¶ğŸ˜ğŸ§ğŸœğŸ’ƒğŸ§ ğŸ¥•â€œğŸ˜‚ğŸš‘ğŸ™„ğŸ•°ã€‚ğŸ¤·Ã·ğŸ˜Ã£^ğŸŒ´ğŸ“šğŸ’¦ğŸ˜ğŸ˜¬å¸ğŸ‘§ğŸ‡ªğŸ©éƒ¨â€¦ğŸ˜‹ğŸ°ğŸŒ§ğŸ¤œğŸŒ»â–¡ğŸ¤¢â€™ğŸ˜…ã¾ğŸ•ğŸ˜­ğŸ™ğŸ’æ—¶ğŸ¢ğŸ›£ğŸŸğŸ‘¦ğŸ§¦ğŸ¥¯ğŸ”¬ğŸ¬Ã©ğŸ•¹ğŸš£ğŸ‡ºæ‰€â•¯ğŸ’”ğŸ‘€æ‰‹ğŸ‘¨å½±ğŸ’¨ğŸ˜“ğŸ¤\ude39ğŸ¨ğŸ¤›ğŸŒ³ğŸ’–ğŸ«ğŸ¤˜ã™ğŸ™ŠğŸ‡µğŸ”‘ğŸ“ğŸ£ğŸ‹åœ¨ğŸ‡§ğŸŒ·ã‚ã†ğŸ»ğŸ¥–Ã³ğŸ»ğŸ„ğŸ“§ğŸ˜˜ğŸ§–ğŸ˜·ğŸ¥¦Ã­ã¯ğŸ¸ğŸš‚ğŸ¥”ğŸ½ğŸ›€ğŸ˜–ğŸ­ğŸ˜¢ğŸ¤¤ğŸ”®ğŸ“±ğŸ§­ğŸµğŸŒ é©¾ğŸ¸ğŸ•’ğŸ¤¦ã›ğŸğŸ¾ğŸ™ğŸ¥é©¶ğŸ¼ğŸššğŸ§¡ğŸ£Â¬ã«ğŸš¨å°†é¡»ğŸŒ«ğŸ„ğŸ‡«ğŸ ğŸ§‘ğŸ§ğŸˆğŸ‘¬ğŸ¤“ğŸ’¡ğŸŒ½ğŸ˜ ğŸ˜œğŸ“„ğŸ„ğŸ€â€ğŸŒƒâ€‹ğŸ¨åˆğŸ˜´æ³¨ğŸ¥—ğŸ¬ğŸ—ğŸ—³ğŸ—£ä¸€ğŸ”ğŸ‘¥â˜€ğŸ”§å”¯ï¸ğŸ’‡ğŸ™ˆğŸ‡¯ğŸ‘«ğŸ§™ğŸ“¦ğŸ”œğŸ˜„ğŸ˜†ğŸšªâ°ğŸ“ºâš½ğŸŒ®ğŸ“Šå…¨ğŸ¥¤ğŸ½ğŸ’…ğŸ¤”ä¿ğŸŒğŸ’ªæ­¢ğŸ’«Ã¼ğŸ‘ğŸ‡·ğŸ’€ğŸ¹ğŸ’¤ğŸ“ğŸ¥‘ğŸ¥©ğŸ˜±æ„ğŸ·ğŸ¤–ğŸ•µğŸ­ğŸ’ğŸŒğŸ˜µæ‹©ğŸ§©é›†ğŸƒğŸ”ğŸœğŸŒŒæœ‰ğŸŒ¯ğŸ˜ƒğŸŒ±ğŸ˜‰ğŸ›¸ğŸ¡ğŸ›å–ğŸ’†ğŸ“…ğŸ‘‡ğŸ‰å®‰â€“ğŸğŸ‘»ğŸ‡¸ğŸ¦ğŸ¤ğŸ˜ŠğŸ’¯ğŸ¥­ğŸ­é“ğŸ›‘ğŸ´ğŸŒ„ãŒğŸ•ºğŸ¦ğŸ‘‚ğŸ’»ğŸŒŠğŸ’§ğŸ“¹ğŸ†ğŸ˜¨ğŸ ğŸ’¬ğŸ²ã‚“ğŸ“¸æ˜¯ğŸ‘‹ç”¨ğŸ±ğŸ¢ğŸ’°ğŸˆå’ŒğŸ™€ğŸ¤«ç¦ğŸ‘ªğŸ“ğŸ¥œğŸ¤©ğŸ§šğŸ°ğŸ \n","output_type":"stream"}]},{"cell_type":"code","source":"translation_table = str.maketrans('', '', chars_to_remove)\ndef remove_chars(s):\n    return s.translate(translation_table)\nnot_persuade_df['text'] = not_persuade_df['text'].apply(remove_chars)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:51.463803Z","iopub.execute_input":"2023-11-24T15:16:51.464210Z","iopub.status.idle":"2023-11-24T15:16:51.942795Z","shell.execute_reply.started":"2023-11-24T15:16:51.464176Z","shell.execute_reply":"2023-11-24T15:16:51.940532Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/2013655814.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  not_persuade_df['text'] = not_persuade_df['text'].apply(remove_chars)\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.concat([not_persuade_df, sampled_persuade_df]).sample(frac=1, random_state=42).reset_index(drop=True)\ntrain.source.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:51.945459Z","iopub.execute_input":"2023-11-24T15:16:51.946202Z","iopub.status.idle":"2023-11-24T15:16:51.982937Z","shell.execute_reply.started":"2023-11-24T15:16:51.946147Z","shell.execute_reply":"2023-11-24T15:16:51.981768Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"source\npersuade_corpus                       6000\nllama2_chat                           2411\nchat_gpt_moth                         2409\nmistral7binstruct_v1                  2408\nmistral7binstruct_v2                  2406\nllama_70b_v1                           984\ndarragh_claude_v6                      952\ndarragh_claude_v7                      951\nfalcon_180b_v1                         899\nkingki19_palm                          672\ntrain_essays                           670\ncohere-command                         301\npalm-text-bison1                       300\nradek_500                              250\nmistralai/Mistral-7B-Instruct-v0.1     201\nNousResearch/Llama-2-7b-chat-hf        200\nradekgpt4                              100\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"ds_train = Dataset.from_pandas(train)\nds_valid = Dataset.from_pandas(valid)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:51.984418Z","iopub.execute_input":"2023-11-24T15:16:51.984895Z","iopub.status.idle":"2023-11-24T15:16:52.165532Z","shell.execute_reply.started":"2023-11-24T15:16:51.984863Z","shell.execute_reply":"2023-11-24T15:16:52.164600Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"ds_train","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:52.168944Z","iopub.execute_input":"2023-11-24T15:16:52.169404Z","iopub.status.idle":"2023-11-24T15:16:52.175696Z","shell.execute_reply.started":"2023-11-24T15:16:52.169363Z","shell.execute_reply":"2023-11-24T15:16:52.174839Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'label', 'prompt_name', 'source', 'RDizzl3_seven'],\n    num_rows: 22114\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:52.177541Z","iopub.execute_input":"2023-11-24T15:16:52.178733Z","iopub.status.idle":"2023-11-24T15:16:54.451100Z","shell.execute_reply.started":"2023-11-24T15:16:52.178698Z","shell.execute_reply":"2023-11-24T15:16:54.450170Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples['text'], max_length=128, padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:54.452679Z","iopub.execute_input":"2023-11-24T15:16:54.454041Z","iopub.status.idle":"2023-11-24T15:16:54.459971Z","shell.execute_reply.started":"2023-11-24T15:16:54.453996Z","shell.execute_reply":"2023-11-24T15:16:54.458751Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"ds_train_enc = ds_train.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:16:54.461689Z","iopub.execute_input":"2023-11-24T15:16:54.462295Z","iopub.status.idle":"2023-11-24T15:17:11.522830Z","shell.execute_reply.started":"2023-11-24T15:16:54.462233Z","shell.execute_reply":"2023-11-24T15:17:11.521805Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b95181ca48aa44eda0c4598da78cf812"}},"metadata":{}}]},{"cell_type":"code","source":"ds_valid_enc = ds_valid.map(preprocess_function , batched = True)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:17:11.524285Z","iopub.execute_input":"2023-11-24T15:17:11.524894Z","iopub.status.idle":"2023-11-24T15:17:16.652030Z","shell.execute_reply.started":"2023-11-24T15:17:11.524860Z","shell.execute_reply":"2023-11-24T15:17:16.650761Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"294e058b5e5d408cb931a9a2e028223d"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nnum_labels = 2\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels = num_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:17:16.653983Z","iopub.execute_input":"2023-11-24T15:17:16.654425Z","iopub.status.idle":"2023-11-24T15:17:36.251848Z","shell.execute_reply.started":"2023-11-24T15:17:16.654384Z","shell.execute_reply":"2023-11-24T15:17:36.250124Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall and are newly initialized: ['pooler.dense.weight', 'classifier.weight', 'classifier.bias', 'pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"metric_name  =\"roc_auc\"\nmodel_name = \"deberta-xsmall\"\ntrain_batch_size = 4\neval_batch_size = 32\ngrad_acc =4","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:17:36.254002Z","iopub.execute_input":"2023-11-24T15:17:36.255225Z","iopub.status.idle":"2023-11-24T15:17:36.263977Z","shell.execute_reply.started":"2023-11-24T15:17:36.255164Z","shell.execute_reply":"2023-11-24T15:17:36.262525Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"num_steps = len(train)//(train_batch_size * grad_acc)\nnum_steps","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:17:36.265993Z","iopub.execute_input":"2023-11-24T15:17:36.267489Z","iopub.status.idle":"2023-11-24T15:17:36.329475Z","shell.execute_reply.started":"2023-11-24T15:17:36.267434Z","shell.execute_reply":"2023-11-24T15:17:36.327964Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"1382"},"metadata":{}}]},{"cell_type":"code","source":"args = TrainingArguments(\n    f\"{model_name}-finetuned\",\n    evaluation_strategy = \"steps\",\n    save_strategy= \"steps\",\n    eval_steps = num_steps //3,\n    save_steps = num_steps //3,\n    learning_rate=2e-5,\n    per_device_train_batch_size = train_batch_size,\n    per_device_eval_batch_size = eval_batch_size,\n    gradient_accumulation_steps = grad_acc,\n    num_train_epochs =1,\n    weight_decay = 0.01,\n    load_best_model_at_end = False,\n    metric_for_best_model = metric_name,\n    report_to ='none',)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:17:36.331352Z","iopub.execute_input":"2023-11-24T15:17:36.331751Z","iopub.status.idle":"2023-11-24T15:17:36.344265Z","shell.execute_reply.started":"2023-11-24T15:17:36.331719Z","shell.execute_reply":"2023-11-24T15:17:36.342977Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    probs = np.exp(logits) / np.sum(np.exp(logits), axis = -1, keepdims = True)\n    auc = roc_auc_score(labels, probs[:,1], multi_class = 'ovr')\n    return {\"roc_auc\": auc}\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:17:36.346233Z","iopub.execute_input":"2023-11-24T15:17:36.347039Z","iopub.status.idle":"2023-11-24T15:17:36.356584Z","shell.execute_reply.started":"2023-11-24T15:17:36.346993Z","shell.execute_reply":"2023-11-24T15:17:36.354932Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset = ds_train_enc,\n    eval_dataset = ds_valid_enc,\n    tokenizer = tokenizer,\n    compute_metrics = compute_metrics)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:17:36.358209Z","iopub.execute_input":"2023-11-24T15:17:36.359559Z","iopub.status.idle":"2023-11-24T15:17:36.390453Z","shell.execute_reply.started":"2023-11-24T15:17:36.359482Z","shell.execute_reply":"2023-11-24T15:17:36.389406Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:17:36.392225Z","iopub.execute_input":"2023-11-24T15:17:36.392640Z","iopub.status.idle":"2023-11-24T17:43:43.978671Z","shell.execute_reply.started":"2023-11-24T15:17:36.392608Z","shell.execute_reply":"2023-11-24T17:43:43.977558Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1382' max='1382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1382/1382 2:26:00, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>460</td>\n      <td>No log</td>\n      <td>0.329228</td>\n      <td>0.993091</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.151300</td>\n      <td>0.179845</td>\n      <td>0.999158</td>\n    </tr>\n    <tr>\n      <td>1380</td>\n      <td>0.049900</td>\n      <td>0.255289</td>\n      <td>0.997103</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1382, training_loss=0.081633302823852, metrics={'train_runtime': 8767.1164, 'train_samples_per_second': 2.522, 'train_steps_per_second': 0.158, 'total_flos': 364157494247424.0, 'train_loss': 0.081633302823852, 'epoch': 1.0})"},"metadata":{}}]}]}