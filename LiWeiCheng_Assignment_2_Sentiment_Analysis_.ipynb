{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiRaaPrc5HSV",
        "outputId": "93cc8355-1817-406f-c54a-32f7c21e2c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/gdrive/My Drive/DecisionTree/DataMining509/IMDB Dataset.csv')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zrjdBHdE6__Q",
        "outputId": "4f884970-31fd-471c-9919-b47d52b8f383"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22213193-0d1f-46a1-b608-6fa4d2a8878d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22213193-0d1f-46a1-b608-6fa4d2a8878d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22213193-0d1f-46a1-b608-6fa4d2a8878d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22213193-0d1f-46a1-b608-6fa4d2a8878d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 1: Data preprocessing\n",
        "import spacy\n",
        "\n",
        "spacy.cli.download(\"en_core_web_sm\")\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL_ZgQ_o8IgE",
        "outputId": "d3a0ca19-7726-4f59-b6fb-79151c37b88e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(review, lowercase, remove_stopwords):\n",
        "  if lowercase:\n",
        "    review = review.lower()\n",
        "  doc = nlp(review)\n",
        "  lemmatized =list()\n",
        "  for token in doc:\n",
        "    if not (remove_stopwords) or (remove_stopwords and not token.is_stop):\n",
        "      lemmatized.append(token.lemma_)\n",
        "  return \" \".join(lemmatized)\n",
        "data['review'] = data['review'].apply(normalize, lowercase =True, remove_stopwords =True)"
      ],
      "metadata": {
        "id": "w42msKhb9oZ4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(data['sentiment'])\n",
        "data['sentiment'] = label_encoder.transform(data['sentiment'])"
      ],
      "metadata": {
        "id": "f7kKrsmw8I7Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data['review'], data['sentiment'], test_size=0.2, random_state=10, stratify=data['sentiment'])\n"
      ],
      "metadata": {
        "id": "CtW2-nBfAmfo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 2: Lexicon-based sentiment analysis\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.downloader.download('vader_lexicon')\n",
        "sentiment = SentimentIntensityAnalyzer()\n",
        "v_predicted = []\n",
        "for text in X_test: \n",
        "  sent= sentiment.polarity_scores(text)\n",
        "  if sent['compound']>0.5: \n",
        "    v_predicted.append('positive')\n",
        "  else:\n",
        "    v_predicted.append('negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK8pDVWlIH2P",
        "outputId": "50f19e6a-1894-4b60-b6ba-d10f1f64d23e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "v_performance = metrics.classification_report(Y_test,v_predicted, target_names= ['negative', 'positive'])\n",
        "print(v_performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3SGA04lJcO_",
        "outputId": "2dd0ecc7-605f-4322-b6b2-4ba6188e5ee4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.56      0.65      5108\n",
            "    positive       0.64      0.82      0.72      4892\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.70      0.69      0.68     10000\n",
            "weighted avg       0.70      0.69      0.68     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3: Naive Bayes model for sentiment analysis (Best model)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range=(1,1), tokenizer = token.tokenize, max_features=1000)\n",
        "X_train_vect = cv.fit_transform(X_train)\n",
        "X_train_vect.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXUPOxIUJwp3",
        "outputId": "4f56bfa7-3538-45f5-efe1-5b3989c9f5d4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(X_train_vect.toarray(), columns=cv.get_feature_names_out())\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "y9y0ZMzFO-1O",
        "outputId": "de900f95-cf11-4652-b50b-170c6de371e0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   1  10  100  15  2  20  3  30  4  5  ...  write  writer  writing  wrong  \\\n",
              "0  0   0    0   0  0   0  0   0  0  0  ...      0       0        0      0   \n",
              "1  0   0    0   0  0   0  0   0  0  0  ...      0       0        0      0   \n",
              "2  0   0    0   0  0   0  0   0  0  0  ...      0       0        0      0   \n",
              "3  0   0    0   0  0   0  0   0  0  0  ...      0       0        0      0   \n",
              "4  0   0    0   0  0   0  0   0  0  0  ...      1       0        0      0   \n",
              "\n",
              "   yeah  year  yes  york  young  zombie  \n",
              "0     0     0    0     0      0       0  \n",
              "1     0     0    0     0      0       0  \n",
              "2     0     0    0     0      0       0  \n",
              "3     0     0    0     0      0       0  \n",
              "4     0     0    0     0      0       0  \n",
              "\n",
              "[5 rows x 1000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e83b4347-f743-4d97-ac28-fb620ec0f624\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>15</th>\n",
              "      <th>2</th>\n",
              "      <th>20</th>\n",
              "      <th>3</th>\n",
              "      <th>30</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>...</th>\n",
              "      <th>write</th>\n",
              "      <th>writer</th>\n",
              "      <th>writing</th>\n",
              "      <th>wrong</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>yes</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>zombie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e83b4347-f743-4d97-ac28-fb620ec0f624')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e83b4347-f743-4d97-ac28-fb620ec0f624 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e83b4347-f743-4d97-ac28-fb620ec0f624');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vect= cv.transform(X_test)\n",
        "X_test_vect.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrGNcg5bOWrV",
        "outputId": "660b4fe2-945f-435c-86a9-36466e6d3798"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train_vect, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "6-QYW4R-Qa3S",
        "outputId": "cef5e279-a4d9-4ab1-99cb-c44c4389e00a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = MNB.predict(X_test_vect)\n",
        "performance = metrics.classification_report(Y_test,predicted, target_names= ['0', '1'])\n",
        "print(performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTbsU3BLQdfJ",
        "outputId": "8f5db9eb-735b-41f1-9772-d841b9b3a23a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83      5108\n",
            "           1       0.81      0.85      0.83      4892\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Second attempt, max_features=500\n",
        "cv = CountVectorizer(stop_words='english',ngram_range=(1,1), tokenizer = token.tokenize, max_features=500)\n",
        "X_train_vect = cv.fit_transform(X_train)\n",
        "X_test_vect= cv.transform(X_test)\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train_vect, Y_train)\n",
        "predicted = MNB.predict(X_test_vect)\n",
        "performance = metrics.classification_report(Y_test,predicted, target_names= ['0', '1'])\n",
        "print(performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-7Ob5HbT9RT",
        "outputId": "7b33b1a2-dce2-44dd-afc4-8cdb6f17eadb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.79      0.81      5108\n",
            "           1       0.79      0.83      0.81      4892\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.81      0.81      0.81     10000\n",
            "weighted avg       0.81      0.81      0.81     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Third attempt, max_features=500 using bigrams instead of unigrams\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range=(2,2), tokenizer = token.tokenize, max_features=500)\n",
        "X_train_vect = cv.fit_transform(X_train)\n",
        "X_test_vect= cv.transform(X_test)\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train_vect, Y_train)\n",
        "predicted = MNB.predict(X_test_vect)\n",
        "performance = metrics.classification_report(Y_test,predicted, target_names= ['0', '1'])\n",
        "print(performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TnGWktuURHo",
        "outputId": "a7fa5f88-a688-49cb-db38-795b61b45d53"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.67      0.72      5108\n",
            "           1       0.70      0.80      0.75      4892\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.73      0.73     10000\n",
            "weighted avg       0.74      0.73      0.73     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#By using Countvectorizer with max_feature =1000 and unigrams, it performs the best f1-score with 0.83 than the other trials in naive_bayes algorithm."
      ],
      "metadata": {
        "id": "2H8WhwjzUpqu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 4: SVM model for sentiment analysis (best model)\n",
        "from sklearn import svm\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range=(1,1), tokenizer = token.tokenize, max_features=1000)\n",
        "X_train_vect = cv.fit_transform(X_train)\n",
        "X_test_vect= cv.transform(X_test)\n",
        "\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train_vect, Y_train)\n",
        "\n",
        "predicted = clf.predict(X_test_vect)\n",
        "performance = metrics.classification_report(Y_test,predicted, target_names= ['0', '1'])\n",
        "print(performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0NMSWQxUTjU",
        "outputId": "82e9d366-cac2-4356-dc00-183e923c5e68"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.83      0.86      5108\n",
            "           1       0.84      0.89      0.86      4892\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Second attempt, with ngram_range=(1,1) & max_features=500\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range=(1,1), tokenizer = token.tokenize, max_features=500)\n",
        "X_train_vect = cv.fit_transform(X_train)\n",
        "X_test_vect= cv.transform(X_test)\n",
        "\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train_vect, Y_train)\n",
        "\n",
        "predicted = clf.predict(X_test_vect)\n",
        "performance = metrics.classification_report(Y_test,predicted, target_names= ['0', '1'])\n",
        "print(performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuD40mpLVvKG",
        "outputId": "f7f08bd0-eb43-4cca-b4a3-15009712ab97"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.81      0.84      5108\n",
            "           1       0.82      0.87      0.84      4892\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Third attempt , with ngram_range=(2,2) & max_features=1000\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range=(2,2), tokenizer = token.tokenize, max_features=1000)\n",
        "X_train_vect = cv.fit_transform(X_train)\n",
        "X_test_vect= cv.transform(X_test)\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train_vect, Y_train)\n",
        "\n",
        "predicted = clf.predict(X_test_vect)\n",
        "performance = metrics.classification_report(Y_test,predicted, target_names= ['0', '1'])\n",
        "print(performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYNg5kNjWs9Z",
        "outputId": "86bfbd16-df25-45f2-8924-5c60d787eb03"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.66      0.73      5108\n",
            "           1       0.70      0.85      0.77      4892\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#By using Countvectorizer with max_feature =1000 and unigrams, it performs the best f1-score with 0.86 than the other trials in SVM algorithm."
      ],
      "metadata": {
        "id": "Za_sCDWaElsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 5: Deep Learning Models for Sentiment Analysis \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "embedding_dim = 100\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\" # out of vocabulary\n",
        "\n",
        "# tokenize sentences\n",
        "tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# convert train dataset to sequence and pad sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "train_padded = pad_sequences(train_sequences, truncating= trunc_type, padding=padding_type, maxlen=max_length)\n",
        "\n",
        "# convert validation dataset to sequence and pad sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded = pad_sequences(test_sequences, truncating= trunc_type, padding=padding_type, maxlen=max_length)\n",
        "\n",
        "\n",
        "vocab_size = len(word_index)"
      ],
      "metadata": {
        "id": "sH_RPuZYGf3z"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "c2ALkRYbZi-L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best model\n",
        "blstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(word_index) + 1, embedding_dim, input_length=max_length, trainable=False),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "blstm.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "\n",
        "blstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CViMr9o-mt3",
        "outputId": "d27cdb00-8ebb-4b70-8ff4-b5caa95738d6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 120, 100)          8333200   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              84480     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                3096      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,420,801\n",
            "Trainable params: 87,601\n",
            "Non-trainable params: 8,333,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Attention, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, mode='min', restore_best_weights=True)\n",
        "\n",
        "num_epochs = 50\n",
        "history = blstm.fit(train_padded, Y_train, \n",
        "                    epochs=num_epochs, verbose=1, callbacks=[early_stop],\n",
        "                    validation_split=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVjKXKd8GfZf",
        "outputId": "a39472ac-e4cc-4d93-ade4-ef7a525e4801"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "875/875 [==============================] - 129s 140ms/step - loss: 0.6481 - accuracy: 0.6110 - f1_m: 0.6058 - precision_m: 0.5991 - recall_m: 0.6716 - val_loss: 0.6320 - val_accuracy: 0.6338 - val_f1_m: 0.6946 - val_precision_m: 0.5866 - val_recall_m: 0.8679\n",
            "Epoch 2/50\n",
            "875/875 [==============================] - 126s 144ms/step - loss: 0.6067 - accuracy: 0.6676 - f1_m: 0.6739 - precision_m: 0.6598 - recall_m: 0.7162 - val_loss: 0.5988 - val_accuracy: 0.6745 - val_f1_m: 0.6810 - val_precision_m: 0.6507 - val_recall_m: 0.7278\n",
            "Epoch 3/50\n",
            "875/875 [==============================] - 125s 143ms/step - loss: 0.5851 - accuracy: 0.6867 - f1_m: 0.6926 - precision_m: 0.6746 - recall_m: 0.7337 - val_loss: 0.5986 - val_accuracy: 0.6718 - val_f1_m: 0.7203 - val_precision_m: 0.6168 - val_recall_m: 0.8811\n",
            "Epoch 4/50\n",
            "875/875 [==============================] - 127s 145ms/step - loss: 0.5688 - accuracy: 0.7009 - f1_m: 0.7068 - precision_m: 0.6904 - recall_m: 0.7464 - val_loss: 0.5838 - val_accuracy: 0.6988 - val_f1_m: 0.6626 - val_precision_m: 0.7304 - val_recall_m: 0.6200\n",
            "Epoch 5/50\n",
            "875/875 [==============================] - 127s 145ms/step - loss: 0.5554 - accuracy: 0.7127 - f1_m: 0.7157 - precision_m: 0.7054 - recall_m: 0.7487 - val_loss: 0.5819 - val_accuracy: 0.6862 - val_f1_m: 0.7309 - val_precision_m: 0.6277 - val_recall_m: 0.8901\n",
            "Epoch 6/50\n",
            "875/875 [==============================] - 126s 144ms/step - loss: 0.5448 - accuracy: 0.7211 - f1_m: 0.7253 - precision_m: 0.7112 - recall_m: 0.7607 - val_loss: 0.5503 - val_accuracy: 0.7120 - val_f1_m: 0.7211 - val_precision_m: 0.6819 - val_recall_m: 0.7782\n",
            "Epoch 7/50\n",
            "875/875 [==============================] - 124s 141ms/step - loss: 0.5328 - accuracy: 0.7279 - f1_m: 0.7303 - precision_m: 0.7184 - recall_m: 0.7663 - val_loss: 0.5855 - val_accuracy: 0.6615 - val_f1_m: 0.5247 - val_precision_m: 0.8276 - val_recall_m: 0.3953\n",
            "Epoch 8/50\n",
            "875/875 [==============================] - 122s 140ms/step - loss: 0.5246 - accuracy: 0.7339 - f1_m: 0.7345 - precision_m: 0.7251 - recall_m: 0.7662 - val_loss: 0.5292 - val_accuracy: 0.7343 - val_f1_m: 0.7091 - val_precision_m: 0.7526 - val_recall_m: 0.6810\n",
            "Epoch 9/50\n",
            "875/875 [==============================] - 126s 144ms/step - loss: 0.5070 - accuracy: 0.7496 - f1_m: 0.7524 - precision_m: 0.7387 - recall_m: 0.7849 - val_loss: 0.5185 - val_accuracy: 0.7462 - val_f1_m: 0.7455 - val_precision_m: 0.7248 - val_recall_m: 0.7793\n",
            "Epoch 10/50\n",
            "875/875 [==============================] - 126s 145ms/step - loss: 0.4940 - accuracy: 0.7577 - f1_m: 0.7591 - precision_m: 0.7482 - recall_m: 0.7890 - val_loss: 0.5208 - val_accuracy: 0.7448 - val_f1_m: 0.7612 - val_precision_m: 0.6997 - val_recall_m: 0.8475\n",
            "Epoch 11/50\n",
            "875/875 [==============================] - 120s 137ms/step - loss: 0.4808 - accuracy: 0.7645 - f1_m: 0.7655 - precision_m: 0.7562 - recall_m: 0.7937 - val_loss: 0.5000 - val_accuracy: 0.7571 - val_f1_m: 0.7471 - val_precision_m: 0.7529 - val_recall_m: 0.7527\n",
            "Epoch 12/50\n",
            "875/875 [==============================] - 124s 142ms/step - loss: 0.4683 - accuracy: 0.7735 - f1_m: 0.7735 - precision_m: 0.7640 - recall_m: 0.7992 - val_loss: 0.4960 - val_accuracy: 0.7581 - val_f1_m: 0.7389 - val_precision_m: 0.7730 - val_recall_m: 0.7189\n",
            "Epoch 13/50\n",
            "875/875 [==============================] - 120s 137ms/step - loss: 0.4568 - accuracy: 0.7816 - f1_m: 0.7818 - precision_m: 0.7759 - recall_m: 0.8051 - val_loss: 0.5244 - val_accuracy: 0.7597 - val_f1_m: 0.7719 - val_precision_m: 0.7152 - val_recall_m: 0.8509\n",
            "Epoch 14/50\n",
            "875/875 [==============================] - 126s 144ms/step - loss: 0.4477 - accuracy: 0.7853 - f1_m: 0.7848 - precision_m: 0.7790 - recall_m: 0.8078 - val_loss: 0.4882 - val_accuracy: 0.7597 - val_f1_m: 0.7620 - val_precision_m: 0.7337 - val_recall_m: 0.8041\n",
            "Epoch 15/50\n",
            "875/875 [==============================] - 123s 141ms/step - loss: 0.4340 - accuracy: 0.7964 - f1_m: 0.7951 - precision_m: 0.7919 - recall_m: 0.8142 - val_loss: 0.4930 - val_accuracy: 0.7611 - val_f1_m: 0.7749 - val_precision_m: 0.7143 - val_recall_m: 0.8588\n",
            "Epoch 16/50\n",
            "875/875 [==============================] - 124s 142ms/step - loss: 0.4211 - accuracy: 0.8039 - f1_m: 0.8020 - precision_m: 0.7985 - recall_m: 0.8205 - val_loss: 0.4936 - val_accuracy: 0.7598 - val_f1_m: 0.7398 - val_precision_m: 0.7772 - val_recall_m: 0.7159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = blstm.evaluate(test_padded, Y_test, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3MZ8gOMPhIy",
        "outputId": "08cf27c2-1a33-49cf-fa80-24916bbdd319"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 14s 42ms/step - loss: 0.4920 - accuracy: 0.7598 - f1_m: 0.7627 - precision_m: 0.7391 - recall_m: 0.7999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#second attemp, tf.keras.layers.Dense(32, activation='relu'),\n",
        "blstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(word_index) + 1, embedding_dim, input_length=max_length, trainable=False),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "blstm.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "\n",
        "blstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On5K5tnDDqD-",
        "outputId": "e0b2f5bc-4e8f-4f23-dca7-315733cf04b1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 120, 100)          8333200   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 128)              84480     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,421,841\n",
            "Trainable params: 88,641\n",
            "Non-trainable params: 8,333,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, mode='min', restore_best_weights=True)\n",
        "\n",
        "num_epochs = 50\n",
        "history = blstm.fit(train_padded, Y_train, \n",
        "                    epochs=num_epochs, verbose=1, callbacks=[early_stop],\n",
        "                    validation_split=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX8IOqn7D0fp",
        "outputId": "2d3dceb5-87f2-42dd-ec19-a987bc887db2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "875/875 [==============================] - 146s 163ms/step - loss: 0.6556 - accuracy: 0.6014 - f1_m: 0.5938 - precision_m: 0.5809 - recall_m: 0.6698 - val_loss: 0.6336 - val_accuracy: 0.6320 - val_f1_m: 0.6950 - val_precision_m: 0.5860 - val_recall_m: 0.8719\n",
            "Epoch 2/50\n",
            "875/875 [==============================] - 159s 181ms/step - loss: 0.6152 - accuracy: 0.6568 - f1_m: 0.6671 - precision_m: 0.6452 - recall_m: 0.7176 - val_loss: 0.5963 - val_accuracy: 0.6733 - val_f1_m: 0.6779 - val_precision_m: 0.6558 - val_recall_m: 0.7159\n",
            "Epoch 3/50\n",
            "875/875 [==============================] - 127s 146ms/step - loss: 0.5907 - accuracy: 0.6816 - f1_m: 0.6921 - precision_m: 0.6681 - recall_m: 0.7409 - val_loss: 0.5883 - val_accuracy: 0.6806 - val_f1_m: 0.6627 - val_precision_m: 0.6852 - val_recall_m: 0.6561\n",
            "Epoch 4/50\n",
            "875/875 [==============================] - 128s 147ms/step - loss: 0.5731 - accuracy: 0.6999 - f1_m: 0.7091 - precision_m: 0.6864 - recall_m: 0.7540 - val_loss: 0.5718 - val_accuracy: 0.7013 - val_f1_m: 0.7037 - val_precision_m: 0.6827 - val_recall_m: 0.7398\n",
            "Epoch 5/50\n",
            "875/875 [==============================] - 124s 142ms/step - loss: 0.5642 - accuracy: 0.7066 - f1_m: 0.7152 - precision_m: 0.6912 - recall_m: 0.7631 - val_loss: 0.5646 - val_accuracy: 0.7002 - val_f1_m: 0.6796 - val_precision_m: 0.7081 - val_recall_m: 0.6664\n",
            "Epoch 6/50\n",
            "875/875 [==============================] - 126s 144ms/step - loss: 0.5559 - accuracy: 0.7121 - f1_m: 0.7174 - precision_m: 0.7010 - recall_m: 0.7569 - val_loss: 0.5646 - val_accuracy: 0.7032 - val_f1_m: 0.6833 - val_precision_m: 0.7119 - val_recall_m: 0.6699\n",
            "Epoch 7/50\n",
            "875/875 [==============================] - 127s 145ms/step - loss: 0.5453 - accuracy: 0.7205 - f1_m: 0.7266 - precision_m: 0.7063 - recall_m: 0.7674 - val_loss: 0.5635 - val_accuracy: 0.7048 - val_f1_m: 0.6682 - val_precision_m: 0.7377 - val_recall_m: 0.6234\n",
            "Epoch 8/50\n",
            "875/875 [==============================] - 125s 143ms/step - loss: 0.5355 - accuracy: 0.7291 - f1_m: 0.7340 - precision_m: 0.7153 - recall_m: 0.7728 - val_loss: 0.5739 - val_accuracy: 0.6942 - val_f1_m: 0.7351 - val_precision_m: 0.6383 - val_recall_m: 0.8827\n",
            "Epoch 9/50\n",
            "875/875 [==============================] - 127s 145ms/step - loss: 0.5233 - accuracy: 0.7367 - f1_m: 0.7408 - precision_m: 0.7232 - recall_m: 0.7802 - val_loss: 0.5531 - val_accuracy: 0.7142 - val_f1_m: 0.7326 - val_precision_m: 0.6739 - val_recall_m: 0.8173\n",
            "Epoch 10/50\n",
            "875/875 [==============================] - 120s 137ms/step - loss: 0.5115 - accuracy: 0.7470 - f1_m: 0.7511 - precision_m: 0.7331 - recall_m: 0.7894 - val_loss: 0.5428 - val_accuracy: 0.7178 - val_f1_m: 0.7102 - val_precision_m: 0.7107 - val_recall_m: 0.7232\n",
            "Epoch 11/50\n",
            "875/875 [==============================] - 123s 141ms/step - loss: 0.4954 - accuracy: 0.7571 - f1_m: 0.7594 - precision_m: 0.7435 - recall_m: 0.7951 - val_loss: 0.5312 - val_accuracy: 0.7285 - val_f1_m: 0.7317 - val_precision_m: 0.7054 - val_recall_m: 0.7729\n",
            "Epoch 12/50\n",
            "875/875 [==============================] - 120s 137ms/step - loss: 0.4823 - accuracy: 0.7655 - f1_m: 0.7687 - precision_m: 0.7515 - recall_m: 0.8048 - val_loss: 0.5213 - val_accuracy: 0.7422 - val_f1_m: 0.7497 - val_precision_m: 0.7105 - val_recall_m: 0.8066\n",
            "Epoch 13/50\n",
            "875/875 [==============================] - 127s 145ms/step - loss: 0.4698 - accuracy: 0.7739 - f1_m: 0.7766 - precision_m: 0.7607 - recall_m: 0.8087 - val_loss: 0.5475 - val_accuracy: 0.7208 - val_f1_m: 0.6855 - val_precision_m: 0.7601 - val_recall_m: 0.6371\n",
            "Epoch 14/50\n",
            "875/875 [==============================] - 123s 141ms/step - loss: 0.4598 - accuracy: 0.7817 - f1_m: 0.7835 - precision_m: 0.7711 - recall_m: 0.8140 - val_loss: 0.5227 - val_accuracy: 0.7531 - val_f1_m: 0.7486 - val_precision_m: 0.7403 - val_recall_m: 0.7702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = blstm.evaluate(test_padded, Y_test, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fbdbMWdD2Ol",
        "outputId": "f89b862b-8cde-4666-9a63-f4f191140a5f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 20s 54ms/step - loss: 0.5220 - accuracy: 0.7419 - f1_m: 0.7572 - precision_m: 0.7048 - recall_m: 0.8301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Third attempt, adding tf.keras.layers.Dense(24, activation='relu')\n",
        "blstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(word_index) + 1, embedding_dim, input_length=max_length, trainable=False),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "blstm.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "\n",
        "blstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCJAnl4REHNX",
        "outputId": "6db8da46-a5d0-4e8b-bd30-b5676781c747"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 120, 100)          8333200   \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 128)              84480     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 24)                792       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,422,625\n",
            "Trainable params: 89,425\n",
            "Non-trainable params: 8,333,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, mode='min', restore_best_weights=True)\n",
        "\n",
        "num_epochs = 50\n",
        "history = blstm.fit(train_padded, Y_train, \n",
        "                    epochs=num_epochs, verbose=1, callbacks=[early_stop],\n",
        "                    validation_split=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPrqQOenERO3",
        "outputId": "aedd1a6a-39b4-40d0-d85d-4dff82de1085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "875/875 [==============================] - 120s 132ms/step - loss: 0.6550 - accuracy: 0.6065 - f1_m: 0.6061 - precision_m: 0.6054 - recall_m: 0.6642 - val_loss: 0.6330 - val_accuracy: 0.6488 - val_f1_m: 0.6538 - val_precision_m: 0.6297 - val_recall_m: 0.6947\n",
            "Epoch 2/50\n",
            "875/875 [==============================] - 118s 135ms/step - loss: 0.6083 - accuracy: 0.6674 - f1_m: 0.6704 - precision_m: 0.6630 - recall_m: 0.7072 - val_loss: 0.6066 - val_accuracy: 0.6637 - val_f1_m: 0.6822 - val_precision_m: 0.6325 - val_recall_m: 0.7548\n",
            "Epoch 3/50\n",
            "875/875 [==============================] - 110s 126ms/step - loss: 0.5927 - accuracy: 0.6778 - f1_m: 0.6856 - precision_m: 0.6682 - recall_m: 0.7294 - val_loss: 0.5909 - val_accuracy: 0.6759 - val_f1_m: 0.7122 - val_precision_m: 0.6287 - val_recall_m: 0.8370\n",
            "Epoch 4/50\n",
            "875/875 [==============================] - 118s 135ms/step - loss: 0.5759 - accuracy: 0.6960 - f1_m: 0.7012 - precision_m: 0.6852 - recall_m: 0.7411 - val_loss: 0.5940 - val_accuracy: 0.6750 - val_f1_m: 0.6825 - val_precision_m: 0.6511 - val_recall_m: 0.7310\n",
            "Epoch 5/50\n",
            "875/875 [==============================] - 118s 135ms/step - loss: 0.5625 - accuracy: 0.7026 - f1_m: 0.7077 - precision_m: 0.6929 - recall_m: 0.7426 - val_loss: 0.5638 - val_accuracy: 0.7053 - val_f1_m: 0.7106 - val_precision_m: 0.6802 - val_recall_m: 0.7574\n",
            "Epoch 6/50\n",
            "875/875 [==============================] - 118s 135ms/step - loss: 0.5523 - accuracy: 0.7144 - f1_m: 0.7139 - precision_m: 0.7096 - recall_m: 0.7411 - val_loss: 0.5641 - val_accuracy: 0.7067 - val_f1_m: 0.6929 - val_precision_m: 0.7067 - val_recall_m: 0.6929\n",
            "Epoch 7/50\n",
            "875/875 [==============================] - 124s 142ms/step - loss: 0.5396 - accuracy: 0.7247 - f1_m: 0.7248 - precision_m: 0.7187 - recall_m: 0.7514 - val_loss: 0.5637 - val_accuracy: 0.7037 - val_f1_m: 0.7149 - val_precision_m: 0.6720 - val_recall_m: 0.7781\n",
            "Epoch 8/50\n",
            "875/875 [==============================] - 123s 141ms/step - loss: 0.5264 - accuracy: 0.7350 - f1_m: 0.7326 - precision_m: 0.7308 - recall_m: 0.7550 - val_loss: 0.5549 - val_accuracy: 0.7098 - val_f1_m: 0.7176 - val_precision_m: 0.6807 - val_recall_m: 0.7720\n",
            "Epoch 9/50\n",
            "875/875 [==============================] - 122s 140ms/step - loss: 0.5146 - accuracy: 0.7419 - f1_m: 0.7405 - precision_m: 0.7373 - recall_m: 0.7617 - val_loss: 0.5519 - val_accuracy: 0.7090 - val_f1_m: 0.6951 - val_precision_m: 0.7085 - val_recall_m: 0.6962\n",
            "Epoch 10/50\n",
            "875/875 [==============================] - 118s 135ms/step - loss: 0.5036 - accuracy: 0.7525 - f1_m: 0.7514 - precision_m: 0.7483 - recall_m: 0.7733 - val_loss: 0.5407 - val_accuracy: 0.7287 - val_f1_m: 0.7306 - val_precision_m: 0.7060 - val_recall_m: 0.7705\n",
            "Epoch 11/50\n",
            "875/875 [==============================] - 125s 143ms/step - loss: 0.4896 - accuracy: 0.7610 - f1_m: 0.7580 - precision_m: 0.7592 - recall_m: 0.7758 - val_loss: 0.5305 - val_accuracy: 0.7308 - val_f1_m: 0.7232 - val_precision_m: 0.7207 - val_recall_m: 0.7392\n",
            "Epoch 12/50\n",
            "875/875 [==============================] - 122s 140ms/step - loss: 0.4772 - accuracy: 0.7716 - f1_m: 0.7689 - precision_m: 0.7721 - recall_m: 0.7839 - val_loss: 0.5453 - val_accuracy: 0.7303 - val_f1_m: 0.7513 - val_precision_m: 0.6801 - val_recall_m: 0.8523\n",
            "Epoch 13/50\n",
            "875/875 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.7817 - f1_m: 0.7775 - precision_m: 0.7832 - recall_m: 0.7893"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = blstm.evaluate(test_padded, Y_test, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYU-EN4kESdH",
        "outputId": "4a495ffb-7e1b-4799-b524-7ebee82645b7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 15s 45ms/step - loss: 0.5193 - accuracy: 0.7367 - f1_m: 0.7315 - precision_m: 0.7286 - recall_m: 0.7464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Conclusion: Using DL methods doesn't mean it will lead to a higher accuracy. The traditional machine learning method with word embedding can generate a better outcome in this case.\n",
        "#Also, lexicon-based Sentiment Analysis performs not very well, maybe because it cannot detect the implicit meaning word by word or sarcasm."
      ],
      "metadata": {
        "id": "6goleXdAYJXN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}